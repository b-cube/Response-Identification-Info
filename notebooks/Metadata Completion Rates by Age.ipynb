{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Does it get better or worse?\n",
    "\n",
    "Presence of elements in ISO/FGDC:\n",
    "\n",
    "- data quality\n",
    "- data quality with lineage\n",
    "- attribute definitions\n",
    "- distribution information\n",
    "- metadata reference section\n",
    "\n",
    "Some of the above will include a word count value extracted from certain elements. For data quality, the count will come from the quality descriptions excluding lineage. The lineage word count will be included separately based on the process step descriptions. Attribute word counts will be taken for FGDC only, and from the main description plus any attribute descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json as js  # name conflict with sqla\n",
    "import sqlalchemy as sqla\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.dialects.postgresql import *\n",
    "from sqlalchemy import and_\n",
    "from semproc.xml_utils import *\n",
    "from mpp.models import Response\n",
    "from datetime import datetime\n",
    "from lxml import etree\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fgdc xpath sets for text extraction\n",
    "\n",
    "# for data quality sans lineage\n",
    "fgdc_dq_xpaths = [\n",
    "    ['dataqual', 'attracc', 'attraccr'],\n",
    "    ['dataqual', 'attracc', 'qattracc', 'attracce'],\n",
    "    ['dataqual', 'logic'],\n",
    "    ['dataqual', 'complete'],\n",
    "    ['dataqual', 'posacc', 'horizpa', 'horizpar'],\n",
    "    ['dataqual', 'posacc', 'horizpa', 'qhorizpa', 'horizpae'],\n",
    "    ['dataqual', 'posacc', 'vertacc', 'vertaccr'],\n",
    "    ['dataqual', 'posacc', 'vertacc', 'qhorizpa', 'vertacce']\n",
    "]\n",
    "\n",
    "# for data quality lineage\n",
    "fgdc_lineage_xpaths = [\n",
    "    ['dataqual', 'lineage', 'procstep', 'procdesc']\n",
    "]\n",
    "\n",
    "# for attributes\n",
    "fgdc_attr_xpaths = [\n",
    "    ['eainfo', 'overview'],\n",
    "    ['eainfo', 'eadetcit'],\n",
    "    ['eainfo', 'detailed', 'attr', 'attrdef'],\n",
    "    ['eainfo', 'detailed', 'attr', 'attrlabl']\n",
    "]\n",
    "\n",
    "# for identifying number of distribution links vs offline resources\n",
    "# xpath returns the number of elements\n",
    "fgdc_distributions = [\n",
    "    ('online_refs', 'count(distinfo/stdorder/digform/digtopt/onlinopt/computer/networka/networkr)'),\n",
    "    ('offline_refs', 'count(distinfo/stdorder/digform/digtopt/offoptn/offmedia)'),\n",
    "    ('nondigital_refs', 'count(distinfo/stdorder/nondig)')\n",
    "]\n",
    "\n",
    "# checks just for a decent existence\n",
    "# mandatory doesn't mean they exist :/\n",
    "fgdc_existences = [\n",
    "    ('data_quality', 'dataqual/logic or dataqual/complete'),\n",
    "    ('lineage', 'count(dataqual/lineage/procstep) > 0'),\n",
    "    ('attribute_ref', 'eainfo/detailed/attrdef or eainfo/detailed/attrlabl'),\n",
    "    ('metadata_ref', 'count(metainfo/metstdn) > 0')  # just check for the standard name\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iso xpath sets\n",
    "\n",
    "# for data quality sans lineage\n",
    "iso_dq_xpaths = [\n",
    "    \n",
    "]\n",
    "\n",
    "# for data quality lineage\n",
    "iso_lineage_xpaths = [\n",
    "    \n",
    "]\n",
    "\n",
    "# for attributes\n",
    "iso_attr_xpaths = [\n",
    "    \n",
    "]\n",
    "\n",
    "iso_existences = [\n",
    "    ()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return a dict of fq xpaths: text from one of our sets\n",
    "# in this case, we aren't interested in element attributes\n",
    "# or in iterating over each child, just elements where\n",
    "# there's an expectation (based on cultural practices)\n",
    "# of finding descriptive text.\n",
    "def extract(xml, xpath):\n",
    "    elems = extract_elems(xml, xpath)\n",
    "    for elem in elems:\n",
    "        text = elem.text if elem.text else ''\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # xpath definition doesn't necessarily include\n",
    "        # every elem name from parent, so return exact path\n",
    "        tags = '/'.join(_taggify(elem))\n",
    "        yield (tags, text.strip())\n",
    "\n",
    "def _extract_tag(t):\n",
    "    if not t:\n",
    "        return\n",
    "    return t.split('}')[-1]\n",
    "\n",
    "def _taggify(e):\n",
    "    tags = [e.tag] + [m.tag for m in e.iterancestors()]\n",
    "    tags.reverse()\n",
    "\n",
    "    try:\n",
    "        return [_extract_tag(t) for t in tags]\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "def convert_to_bag(arr):\n",
    "    # we have some array of strings and we want\n",
    "    # tokens. not going to worry about numbers\n",
    "    # or urns or what have you today.\n",
    "    return ' '.join([a[1] for a in arr]).split()\n",
    "\n",
    "def check_existence(xml, check):\n",
    "    return xml.xpath(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the postgres connection file\n",
    "with open('../local/big_rds.conf', 'r') as f:\n",
    "    conf = js.loads(f.read())\n",
    "\n",
    "# our connection\n",
    "engine = sqla.create_engine(conf.get('connection'))\n",
    "Session = sessionmaker()\n",
    "Session.configure(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sketchy_sql = '''with i\n",
    "as (\n",
    "    select d.response_id, jsonb_array_elements(d.identity::jsonb) ident\n",
    "    from identities d\n",
    "    where d.identity is not null\n",
    ")\n",
    "\n",
    "select r.id, r.source_url, r.source_url_sha, r.cleaned_content, i.ident->'protocol' as protocol\n",
    "from responses r join i on i.response_id = r.id\n",
    "where i.ident->>'protocol' = 'FGDC'\n",
    "limit %s\n",
    "offset %s;\n",
    "'''\n",
    "\n",
    "# where i.ident->>'protocol' = 'FGDC' or i.ident->>'protocol' = 'ISO'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LIMIT=500\n",
    "# for i in xrange(0, 46000, LIMIT):\n",
    "\n",
    "LIMIT = 500\n",
    "for i in xrange(0, 26300, LIMIT):\n",
    "    sql = sketchy_sql % (LIMIT, i)\n",
    "    result = session.execute(sql)\n",
    "    for r in result:\n",
    "        if os.path.exists('outputs/metrics/%s.json' % r['id']):\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            xml = etree.fromstring(r['cleaned_content'].encode('utf-8'))\n",
    "        except:\n",
    "            print 'xml fail', r['id']\n",
    "            continue\n",
    "            \n",
    "        metrics = {\n",
    "            \"data_quality\": False,\n",
    "            \"data_quality_bow\": 0,\n",
    "            \"lineage\": False,\n",
    "            \"lineage_bow\": 0,\n",
    "            \"attribute_ref\": False,\n",
    "            \"attribute_bow\": 0,\n",
    "            \"metadata_ref\": False,\n",
    "            \"distribution\": {}\n",
    "        }\n",
    "\n",
    "        if r['protocol'] == 'ISO':\n",
    "            # \n",
    "            pass\n",
    "        elif r['protocol'] == 'FGDC':\n",
    "            for ename, expath in fgdc_existences:\n",
    "                metrics[ename] = check_existence(xml, expath)\n",
    "            \n",
    "            # data quality\n",
    "            arr = []\n",
    "            for xp in fgdc_dq_xpaths:\n",
    "                arr += [d for d in extract(xml, xp)]\n",
    "            \n",
    "            metrics['data_quality_bow'] = len(convert_to_bag(arr))\n",
    "            \n",
    "            # dataqual lineage\n",
    "            arr = []\n",
    "            for xp in fgdc_lineage_xpaths:\n",
    "                arr += [d for d in extract(xml, xp)]\n",
    "            \n",
    "            metrics['lineage_bow'] = len(convert_to_bag(arr))\n",
    "            \n",
    "            # eainfo\n",
    "            arr = []\n",
    "            for xp in fgdc_attr_xpaths:\n",
    "                arr += [d for d in extract(xml, xp)]\n",
    "            \n",
    "            metrics['attribute_bow'] = len(convert_to_bag(arr))\n",
    "            \n",
    "            # count the kinds of distribution access points\n",
    "            for dname, dxpath in fgdc_distributions:\n",
    "                metrics['distribution'][dname] = check_existence(xml, dxpath)\n",
    "        \n",
    "#         print r['id'], r['source_url']\n",
    "#         print metrics\n",
    "#         print\n",
    "#         print\n",
    "            \n",
    "        with open('outputs/metrics/%s.json' % r['id'], 'w') as g:\n",
    "            g.write(js.dumps(metrics, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
