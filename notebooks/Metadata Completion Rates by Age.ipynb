{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it get better or worse?\n",
    "\n",
    "Presence of elements in ISO/FGDC:\n",
    "\n",
    "- data quality\n",
    "- data quality with lineage\n",
    "- attribute definitions\n",
    "- distribution information\n",
    "- metadata reference section\n",
    "\n",
    "Some of the above will include a word count value extracted from certain elements. For data quality, the count will come from the quality descriptions excluding lineage. The lineage word count will be included separately based on the process step descriptions. Attribute word counts will be taken for FGDC only, and from the main description plus any attribute descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json as js  # name conflict with sqla\n",
    "import sqlalchemy as sqla\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.dialects.postgresql import *\n",
    "from sqlalchemy import and_\n",
    "from semproc.xml_utils import *\n",
    "from mpp.models import Response\n",
    "from datetime import datetime\n",
    "from lxml import etree\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fgdc xpath sets for text extraction\n",
    "\n",
    "# for data quality sans lineage\n",
    "fgdc_dq_xpaths = [\n",
    "    ['dataqual', 'attracc', 'attraccr'],\n",
    "    ['dataqual', 'attracc', 'qattracc', 'attracce'],\n",
    "    ['dataqual', 'logic'],\n",
    "    ['dataqual', 'complete'],\n",
    "    ['dataqual', 'posacc', 'horizpa', 'horizpar'],\n",
    "    ['dataqual', 'posacc', 'horizpa', 'qhorizpa', 'horizpae'],\n",
    "    ['dataqual', 'posacc', 'vertacc', 'vertaccr'],\n",
    "    ['dataqual', 'posacc', 'vertacc', 'qhorizpa', 'vertacce']\n",
    "]\n",
    "\n",
    "# for data quality lineage\n",
    "fgdc_lineage_xpaths = [\n",
    "    ['dataqual', 'lineage', 'procstep', 'procdesc']\n",
    "]\n",
    "\n",
    "# for attributes\n",
    "fgdc_attr_xpaths = [\n",
    "    ['eainfo', 'overview'],\n",
    "    ['eainfo', 'eadetcit'],\n",
    "    ['eainfo', 'detailed', 'attr', 'attrdef'],\n",
    "    ['eainfo', 'detailed', 'attr', 'attrlabl']\n",
    "]\n",
    "\n",
    "# checks just for a decent existence\n",
    "# mandatory doesn't mean they exist :/\n",
    "fgdc_existences = [\n",
    "    ('dataqual', 'dataqual/logic or dataqual/complete'),\n",
    "    ('lineage', 'dataqual/lineage/procstep'),\n",
    "    ('attributes', 'eainfo/detailed/attrdef or eainfo/detailed/attrlabl'),\n",
    "    ('metadata ref', 'metainfo/metstdn')  # just check for the standard name\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iso xpath sets\n",
    "\n",
    "# for data quality sans lineage\n",
    "iso_dq_xpaths = [\n",
    "    \n",
    "]\n",
    "\n",
    "# for data quality lineage\n",
    "iso_lineage_xpaths = [\n",
    "    \n",
    "]\n",
    "\n",
    "# for attributes\n",
    "iso_attr_xpaths = [\n",
    "    \n",
    "]\n",
    "\n",
    "iso_existences = [\n",
    "    ()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return a dict of fq xpaths: text from one of our sets\n",
    "# in this case, we aren't interested in element attributes\n",
    "# or in iterating over each child, just elements where\n",
    "# there's an expectation (based on cultural practices)\n",
    "# of finding descriptive text.\n",
    "def extract(xml, xpath):\n",
    "    elems = extract_elems(xml, xpath)\n",
    "    for elem in elems:\n",
    "        text = elem.text if elem.text else ''\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # xpath definition doesn't necessarily include\n",
    "        # every elem name from parent, so return exact path\n",
    "        tags = '/'.join(_taggify(elem))\n",
    "        yield (tags, text.strip())\n",
    "\n",
    "def _extract_tag(t):\n",
    "    if not t:\n",
    "        return\n",
    "    return t.split('}')[-1]\n",
    "\n",
    "def _taggify(e):\n",
    "    tags = [e.tag] + [m.tag for m in e.iterancestors()]\n",
    "    tags.reverse()\n",
    "\n",
    "    try:\n",
    "        return [_extract_tag(t) for t in tags]\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the postgres connection file\n",
    "with open('../local/big_rds.conf', 'r') as f:\n",
    "    conf = js.loads(f.read())\n",
    "\n",
    "# our connection\n",
    "engine = sqla.create_engine(conf.get('connection'))\n",
    "Session = sessionmaker()\n",
    "Session.configure(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sketchy_sql = '''with i\n",
    "as (\n",
    "    select d.response_id, jsonb_array_elements(d.identity::jsonb) ident\n",
    "    from identities d\n",
    "    where d.identity is not null\n",
    ")\n",
    "\n",
    "select r.id, r.source_url, r.source_url_sha, r.cleaned_content, i.ident->'protocol' as protocol\n",
    "from responses r join i on i.response_id = r.id\n",
    "where i.ident->>'protocol' = 'FGDC' or i.ident->>'protocol' = 'ISO'\n",
    "limit %s\n",
    "offset %s;\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LIMIT=500\n",
    "for i in xrange(0, 46000, LIMIT):\n",
    "    sql = sketchy_sql % (LIMIT, i)\n",
    "    result = session.execute(sql)\n",
    "    for r in result:\n",
    "        if os.path.exists('outputs/metrics/%s.json' % r['id']):\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            xml = etree.fromstring(r['cleaned_content'].encode('utf-8'))\n",
    "        except:\n",
    "            print 'xml fail', r['id']\n",
    "            continue\n",
    "            \n",
    "        metrics = {\n",
    "            \"data_quality\": False,\n",
    "            \"data_quality_bow\": 0,\n",
    "            \"lineage\": False,\n",
    "            \"lineage_bow\": 0,\n",
    "            \"attribute_ref\": False,\n",
    "            \"attribute_bow\": 0\n",
    "            \"metadata_ref\": False,\n",
    "            \"distribution\": False\n",
    "        }\n",
    "\n",
    "        if r['protocol'] == 'ISO':\n",
    "            # \n",
    "        elif r['protocol'] == 'FGDC':\n",
    "            dataqual_elem = extract_elem(xml, ['dataqual'])\n",
    "            if dataqual_elem is not None:\n",
    "                \n",
    "            \n",
    "            # data quality\n",
    "            \n",
    "            # dataqual lineage\n",
    "            \n",
    "            # eainfo\n",
    "            \n",
    "            # metadata ref?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
