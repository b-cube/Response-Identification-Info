{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we identify JSON blobs as freetext in XML elements or attributes?\n",
    "\n",
    "By host, by qualified xpath. Number of XMLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from lxml import etree\n",
    "from semproc.rawresponse import RawResponse\n",
    "from semproc.xml_utils import extract_elems\n",
    "import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_header_list(headers):\n",
    "    return dict(\n",
    "        (k.strip().lower(), v.strip()) for k, v in (\n",
    "            h.split(':', 1) for h in headers)\n",
    "    )\n",
    "\n",
    "def get_xml(response, content_type):\n",
    "    rr = RawResponse(response, content_type)\n",
    "    try:\n",
    "        content = rr.clean_raw_content()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    if rr.datatype != 'xml':\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        return etree.fromstring(content)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    return None\n",
    "\n",
    "# a modified version of the bag parser\n",
    "# we want to return the text and the xpath\n",
    "# of anything that parses as json\n",
    "class XmlParser(object):\n",
    "    def __init__(self, xml):\n",
    "        self.xml = xml\n",
    "        \n",
    "    def _is_json(self, text):\n",
    "        try:\n",
    "            j = json.loads(text)\n",
    "            return isinstance(j, dict)\n",
    "        except:\n",
    "            return False\n",
    "        return False\n",
    "    \n",
    "    def parse(self):\n",
    "        def _extract_tag(t):\n",
    "            if not t:\n",
    "                return\n",
    "            return t.split('}')[-1]\n",
    "\n",
    "        def _taggify(e):\n",
    "            tags = [e.tag] + [m.tag for m in e.iterancestors()]\n",
    "            tags.reverse()\n",
    "\n",
    "            try:\n",
    "                return [_extract_tag(t) for t in tags]\n",
    "            except:\n",
    "                return []\n",
    "        \n",
    "        for elem in self.xml.iter():\n",
    "            t = elem.text.strip() if elem.text else ''\n",
    "            tags = _taggify(elem)\n",
    "            \n",
    "            if t and self._is_json(t):\n",
    "                yield (t, '/'.join(tags))\n",
    "        \n",
    "            for k, v in elem.attrib.iteritems():\n",
    "                a = v.strip()\n",
    "                if a and self._is_json(a):\n",
    "                    yield (a, '/'.join(tags + ['@' + _extract_tag(k)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob('/Users/sparky/Documents/solr_responses/solr_20150922_docs/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished:  0\n",
      "finished:  10000\n",
      "finished:  20000\n",
      "finished:  30000\n",
      "finished:  40000\n",
      "finished:  50000\n",
      "finished:  60000\n",
      "finished:  70000\n",
      "finished:  80000\n",
      "finished:  90000\n",
      "finished:  100000\n",
      "finished:  110000\n",
      "finished:  120000\n",
      "finished:  130000\n",
      "finished:  140000\n",
      "finished:  150000\n",
      "finished:  160000\n",
      "finished:  170000\n",
      "finished:  180000\n",
      "finished:  190000\n",
      "finished:  200000\n",
      "finished:  210000\n",
      "finished:  220000\n",
      "finished:  230000\n",
      "finished:  240000\n",
      "finished:  250000\n",
      "finished:  260000\n",
      "finished:  270000\n",
      "finished:  280000\n",
      "finished:  290000\n",
      "finished:  300000\n",
      "finished:  310000\n",
      "finished:  320000\n",
      "finished:  330000\n",
      "finished:  340000\n",
      "finished:  350000\n",
      "finished:  360000\n",
      "finished:  370000\n",
      "finished:  380000\n",
      "finished:  390000\n",
      "finished:  400000\n",
      "finished:  410000\n",
      "finished:  420000\n",
      "finished:  430000\n",
      "finished:  440000\n",
      "finished:  450000\n",
      "finished:  460000\n",
      "finished:  470000\n",
      "finished:  480000\n",
      "finished:  490000\n",
      "finished:  500000\n",
      "finished:  510000\n",
      "finished:  520000\n",
      "finished:  530000\n",
      "finished:  540000\n",
      "finished:  550000\n",
      "finished:  560000\n",
      "finished:  570000\n",
      "finished:  580000\n",
      "finished:  590000\n",
      "finished:  600000\n",
      "finished:  610000\n",
      "finished:  620000\n",
      "finished:  630000\n",
      "finished:  640000\n",
      "finished:  650000\n",
      "finished:  660000\n",
      "finished:  670000\n"
     ]
    }
   ],
   "source": [
    "PATH = 'outputs/responses_with_json.csv'\n",
    "with open(PATH, 'w') as f:\n",
    "    f.write('file|json|xpath\\n')\n",
    "\n",
    "for i, f in enumerate(files):\n",
    "    if i % 10000 == 0:\n",
    "        print 'finished: ', i\n",
    "    with open(f, 'r') as g:\n",
    "        data = json.loads(g.read())\n",
    "    \n",
    "    response = data.get('raw_content')\n",
    "    headers = convert_header_list(data.get('response_headers', []))\n",
    "    content_type = headers.get('content-type', '')\n",
    "    \n",
    "    xml = get_xml(response, content_type)\n",
    "    if xml is None:\n",
    "        continue\n",
    "    \n",
    "    parser = XmlParser(xml)\n",
    "    jsons = [j for j in parser.parse()]\n",
    "    \n",
    "    if jsons:\n",
    "        with open(PATH, 'a') as g:\n",
    "            for j, x in jsons:\n",
    "                g.write('{0}|{1}|{2}\\n'.format(f, j.replace('|', ';').encode('UTF-8'), x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
