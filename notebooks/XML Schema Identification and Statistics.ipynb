{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the current Solr set as of 2015-09-22T21:00.\n",
    "\n",
    "Initial run to determine:\n",
    "\n",
    "1. How many of the parsable XML responses include a schema location out of the set?\n",
    "2. What are the unique schemas?\n",
    "3. How many are federally-hosted?\n",
    "\n",
    "TODOs:\n",
    "\n",
    "- aggregate by protocol (post-identification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parsing code\n",
    "# note: there's some older cruft to deal with\n",
    "# related to cdata, encodings, etc.\n",
    "\n",
    "_total_responses = 677510\n",
    "_doc_dir = '/Users/sparky/Documents/solr_responses/solr_20150922_docs/'\n",
    "_xpaths = [\n",
    "    ['//*', '@schemaLocation'],\n",
    "    ['//*', '@noNamespaceSchemaLocation']\n",
    "]\n",
    "\n",
    "def generate_localname_xpath(tags):\n",
    "    unchangeds = ['*', '..', '.', '//*']\n",
    "    return '/'.join(\n",
    "        ['%s*[local-name()=\"%s\"]' % ('@' if '@' in t else '', t.replace('@', ''))\n",
    "         if t not in unchangeds else t for t in tags])\n",
    "\n",
    "\n",
    "def extract_attribs(elem, tags):\n",
    "    e = extract_elems(elem, tags)\n",
    "    return list([' '.join(m.strip().split()) for m in e] if isinstance(e, list) else [' '.join(e.split())])\n",
    "\n",
    "\n",
    "def extract_elems(elem, tags):\n",
    "    xp = generate_localname_xpath(tags)\n",
    "    return elem.xpath(xp)\n",
    "\n",
    "\n",
    "def _clean_content(response):\n",
    "    response = response.replace('\\\\\\n', '').replace('\\r\\n', '').replace('\\\\r', '').replace('\\\\n', '').replace('\\n', '')\n",
    "    response = response.replace('\\\\\\t', '').replace('\\\\t', '').replace('\\t', '')\n",
    "    # this is likely useless (mostly issues in the json)\n",
    "    response = response.replace('\\\\\\\\ufffd', '').replace('\\\\\\ufffd', '').replace('\\\\ufffd', '').replace('\\ufffd', '')\n",
    "    response = response.decode('utf-8', errors='replace').encode('unicode_escape') \n",
    "    return response\n",
    "\n",
    "\n",
    "def _parse_content(response):\n",
    "    parser = etree.XMLParser()\n",
    "    return etree.fromstring(response, parser=parser)\n",
    "\n",
    "\n",
    "def prep_content(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    response = data.get('raw_content', '')\n",
    "    response = _clean_content(response)\n",
    "    return _parse_content(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gather the schemas, noting that the method\n",
    "# for extraction does *not* consider failovers\n",
    "# ie, the =\"schema_a.xsd schema_b.xsd\" situation\n",
    "# so we need to handle it after\n",
    "\n",
    "parsed_responses = 0\n",
    "failed_responses = []\n",
    "unique_schemas = set()\n",
    "packed_unique_schemas = set()\n",
    "responses_with_a_schema = 0\n",
    "for i, f in enumerate(glob.glob(_doc_dir + '*.json')):\n",
    "    try:\n",
    "        xml = prep_content(f)\n",
    "        parsed_responses += 1\n",
    "    except Exception as ex:\n",
    "        failed_responses.append((f, ex))\n",
    "        continue\n",
    "    \n",
    "    schemas = []\n",
    "    for xp in _xpaths:\n",
    "        schemas += extract_attribs(xml, xp)\n",
    "\n",
    "    if not schemas:\n",
    "        continue\n",
    "\n",
    "    packed_unique_schemas = packed_unique_schemas.union(set(schemas))\n",
    "    \n",
    "    schemas = [a.strip() for s in schemas for a in s.split()]\n",
    "    unique_schemas = unique_schemas.union(set(schemas))\n",
    "    responses_with_a_schema += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509608"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124769"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_with_a_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167902"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2382"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1960"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(packed_unique_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('outputs/unique_schemas.txt', 'w') as f:\n",
    "    f.write('\\n'.join(list(unique_schemas)))\n",
    "with open('outputs/unique_packed_schemas.txt', 'w') as f:\n",
    "    f.write('\\n'.join(list(packed_unique_schemas)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And here we pause for a bit to do some manual cleanup. From that, we need to reset for unique from our now three schema lists (unique, unique packed, federal). \n",
    "\n",
    "Note: unique is the schema location split by spaces (each schema listed), unique packed is the schema location as is, and federal are the federally-hosted schemas.\n",
    "\n",
    "So re-open, set, sort and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniques:  2366\n",
      "packed uniques:  1960\n",
      "feds:  206\n"
     ]
    }
   ],
   "source": [
    "with open('outputs/unique_schemas.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "unique = sorted(list(set(lines)))\n",
    "with open('outputs/unique_schemas_sorted.txt', 'w') as f:\n",
    "    f.write(''.join(list(unique)))\n",
    "\n",
    "print 'uniques: ', len(unique)\n",
    "\n",
    "with open('outputs/unique_packed_schemas.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "unique = sorted(list(set(lines)))\n",
    "with open('outputs/unique_packed_schemas_sorted.txt', 'w') as f:\n",
    "    f.write(''.join(list(unique)))\n",
    "\n",
    "print 'packed uniques: ', len(unique)\n",
    "\n",
    "with open('outputs/federal_schemas.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "unique = sorted(list(set(lines)))\n",
    "with open('outputs/federal_schemas_sorted.txt', 'w') as f:\n",
    "    f.write(''.join(list(unique)))\n",
    "\n",
    "print 'feds: ', len(unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few more stats from the unique, unpacked list:\n",
    "\n",
    "Relative paths or simple file names: 363"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
